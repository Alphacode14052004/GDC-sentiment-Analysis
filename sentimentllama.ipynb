{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7159440,"sourceType":"datasetVersion","datasetId":4134985},{"sourceId":4295,"sourceType":"modelInstanceVersion","modelInstanceId":3090}],"dockerImageVersionId":30615,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-28T16:40:39.928180Z","iopub.status.idle":"2024-02-28T16:40:39.929317Z","shell.execute_reply.started":"2024-02-28T16:40:39.929030Z","shell.execute_reply":"2024-02-28T16:40:39.929081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -q -U accelerate peft bitsandbytes transformers trl","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.930584Z","iopub.status.idle":"2024-02-28T16:40:39.931004Z","shell.execute_reply.started":"2024-02-28T16:40:39.930797Z","shell.execute_reply":"2024-02-28T16:40:39.930825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.932781Z","iopub.status.idle":"2024-02-28T16:40:39.933387Z","shell.execute_reply.started":"2024-02-28T16:40:39.933175Z","shell.execute_reply":"2024-02-28T16:40:39.933196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.934800Z","iopub.status.idle":"2024-02-28T16:40:39.935203Z","shell.execute_reply.started":"2024-02-28T16:40:39.934998Z","shell.execute_reply":"2024-02-28T16:40:39.935016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig, \n                          TrainingArguments, \n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.936632Z","iopub.status.idle":"2024-02-28T16:40:39.937002Z","shell.execute_reply.started":"2024-02-28T16:40:39.936820Z","shell.execute_reply":"2024-02-28T16:40:39.936837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"/kaggle/input/mental-health-sentiment-analysis/mental_health_sentiment_analysis.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.938283Z","iopub.status.idle":"2024-02-28T16:40:39.938656Z","shell.execute_reply.started":"2024-02-28T16:40:39.938473Z","shell.execute_reply":"2024-02-28T16:40:39.938490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(filename, \n                 names=[\"sentiment\", \"text\"],\n                 encoding=\"utf-8\", encoding_errors=\"replace\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.939652Z","iopub.status.idle":"2024-02-28T16:40:39.940015Z","shell.execute_reply.started":"2024-02-28T16:40:39.939836Z","shell.execute_reply":"2024-02-28T16:40:39.939853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns={\"predicted\": \"sentiment\", \"posts\": \"text\"})","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.941093Z","iopub.status.idle":"2024-02-28T16:40:39.941473Z","shell.execute_reply.started":"2024-02-28T16:40:39.941281Z","shell.execute_reply":"2024-02-28T16:40:39.941298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = list()\nX_test = list()","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.942821Z","iopub.status.idle":"2024-02-28T16:40:39.943216Z","shell.execute_reply.started":"2024-02-28T16:40:39.943012Z","shell.execute_reply":"2024-02-28T16:40:39.943030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sentiment in ['negative', 'neutral', 'positive', 'very negative']:\n    train, test = train_test_split(df[df.sentiment == sentiment],\n                                   train_size=0.7,  \n                                   test_size=0.3,   \n                                   random_state=42)\n    X_train.append(train)\n    X_test.append(test)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.944288Z","iopub.status.idle":"2024-02-28T16:40:39.944662Z","shell.execute_reply.started":"2024-02-28T16:40:39.944479Z","shell.execute_reply":"2024-02-28T16:40:39.944496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.concat(X_train).sample(frac=1, random_state=10)\nX_test = pd.concat(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.946219Z","iopub.status.idle":"2024-02-28T16:40:39.949117Z","shell.execute_reply.started":"2024-02-28T16:40:39.948762Z","shell.execute_reply":"2024-02-28T16:40:39.948792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_idx = [idx for idx in df.index if idx not in list(train.index) + list(test.index)]\nX_eval = df[df.index.isin(eval_idx)]\nX_eval = (X_eval\n          .groupby('sentiment', group_keys=False)\n          .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\nX_train = X_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.950799Z","iopub.status.idle":"2024-02-28T16:40:39.951688Z","shell.execute_reply.started":"2024-02-28T16:40:39.951380Z","shell.execute_reply":"2024-02-28T16:40:39.951407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    return f\"\"\"\n            Analyze the sentiment of the Cancer Survivors & Caregivers in square brackets, \n            determine if it is positive, neutral, negative, or very negative and return the answer as \n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\" or \"very negative\".\n\n            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n            \"\"\".strip()\n\ndef generate_test_prompt(data_point):\n    return f\"\"\"\n            Analyze the sentiment of the Cancer Survivors & Caregivers in square brackets, \n            determine if it is positive, neutral, negative, or very negative and return the answer as \n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\" or \"very negative\".\n\n            [{data_point[\"text\"]}] = \"\"\".strip()","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.953429Z","iopub.status.idle":"2024-02-28T16:40:39.953978Z","shell.execute_reply.started":"2024-02-28T16:40:39.953697Z","shell.execute_reply":"2024-02-28T16:40:39.953723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n                       columns=[\"text\"])\nX_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n                      columns=[\"text\"])\n\ny_true = X_test.sentiment\nX_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n\ntrain_data = Dataset.from_pandas(X_train)\neval_data = Dataset.from_pandas(X_eval)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.955383Z","iopub.status.idle":"2024-02-28T16:40:39.955907Z","shell.execute_reply.started":"2024-02-28T16:40:39.955637Z","shell.execute_reply":"2024-02-28T16:40:39.955662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = ['positive', 'neutral', 'negative', 'very negative']\n    \n    mapping = {'positive': 1, 'neutral': 0, 'negative': -1, 'very negative': -2}\n    \n    def map_func(x):\n        return mapping.get(x, 0)\n    \n    y_true = np.vectorize(map_func)(y_true)\n    y_pred = np.vectorize(map_func)(y_pred)\n    \n    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    unique_labels = set(y_true)  \n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true)) if y_true[i] == label]\n        label_y_true = [y_true[i] for i in label_indices]\n        label_y_pred = [y_pred[i] for i in label_indices]\n        accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {labels[label]}: {accuracy:.3f}')\n        \n    class_report = classification_report(y_true=y_true, y_pred=y_pred, target_names=labels)\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.958273Z","iopub.status.idle":"2024-02-28T16:40:39.958684Z","shell.execute_reply.started":"2024-02-28T16:40:39.958494Z","shell.execute_reply":"2024-02-28T16:40:39.958512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"/kaggle/input/llama-2/pytorch/7b-hf/1\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.959812Z","iopub.status.idle":"2024-02-28T16:40:39.960208Z","shell.execute_reply.started":"2024-02-28T16:40:39.959992Z","shell.execute_reply":"2024-02-28T16:40:39.960009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.961300Z","iopub.status.idle":"2024-02-28T16:40:39.961686Z","shell.execute_reply.started":"2024-02-28T16:40:39.961496Z","shell.execute_reply":"2024-02-28T16:40:39.961514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.962519Z","iopub.status.idle":"2024-02-28T16:40:39.962893Z","shell.execute_reply.started":"2024-02-28T16:40:39.962696Z","shell.execute_reply":"2024-02-28T16:40:39.962713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.963988Z","iopub.status.idle":"2024-02-28T16:40:39.964371Z","shell.execute_reply.started":"2024-02-28T16:40:39.964186Z","shell.execute_reply":"2024-02-28T16:40:39.964203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, \n                                          trust_remote_code=True,\n                                         )\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.965703Z","iopub.status.idle":"2024-02-28T16:40:39.966074Z","shell.execute_reply.started":"2024-02-28T16:40:39.965881Z","shell.execute_reply":"2024-02-28T16:40:39.965898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    y_pred = []\n    for i in tqdm(range(len(X_test))):\n        prompt = X_test.iloc[i][\"text\"]\n        pipe = pipeline(task=\"text-generation\", \n                        model=model, \n                        tokenizer=tokenizer, \n                        max_new_tokens = 1, \n                        temperature = 0.0,\n                       )\n        result = pipe(prompt)\n        answer = result[0]['generated_text'].split(\"=\")[-1]\n        if \"positive\" in answer:\n            y_pred.append(\"positive\")\n        elif \"negative\" in answer:\n            y_pred.append(\"negative\")\n        elif \"neutral\" in answer:\n            y_pred.append(\"neutral\")\n        else:\n            y_pred.append(\"very negative\")\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.967372Z","iopub.status.idle":"2024-02-28T16:40:39.967735Z","shell.execute_reply.started":"2024-02-28T16:40:39.967555Z","shell.execute_reply":"2024-02-28T16:40:39.967572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = predict(test, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.968762Z","iopub.status.idle":"2024-02-28T16:40:39.969128Z","shell.execute_reply.started":"2024-02-28T16:40:39.968932Z","shell.execute_reply":"2024-02-28T16:40:39.968949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.970516Z","iopub.status.idle":"2024-02-28T16:40:39.970884Z","shell.execute_reply.started":"2024-02-28T16:40:39.970696Z","shell.execute_reply":"2024-02-28T16:40:39.970714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"peft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"logs\",\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4, \n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"cosine\",\n    report_to=\"tensorboard\",\n    evaluation_strategy=\"epoch\"\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False,\n    max_seq_length=1024,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T10:15:00.211642Z","iopub.execute_input":"2023-12-10T10:15:00.211876Z","iopub.status.idle":"2023-12-10T10:15:06.204193Z","shell.execute_reply.started":"2023-12-10T10:15:00.211855Z","shell.execute_reply":"2023-12-10T10:15:06.203055Z"}}},{"cell_type":"code","source":"peft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"logs\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,  # Adjust based on your GPU memory\n    gradient_accumulation_steps=4,  # Adjust based on your GPU memory\n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,\n    learning_rate=2e-4,  # Experiment with different learning rates\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"cosine\",\n    report_to=\"tensorboard\",\n    evaluation_strategy=\"epoch\"\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False,\n    max_seq_length=512,  # Adjust based on your requirements and GPU memory\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.971787Z","iopub.status.idle":"2024-02-28T16:40:39.972156Z","shell.execute_reply.started":"2024-02-28T16:40:39.971960Z","shell.execute_reply":"2024-02-28T16:40:39.971977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.model.save_pretrained(\"trained-model\")","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.973618Z","iopub.status.idle":"2024-02-28T16:40:39.973976Z","shell.execute_reply.started":"2024-02-28T16:40:39.973797Z","shell.execute_reply":"2024-02-28T16:40:39.973814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs/runs","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.975085Z","iopub.status.idle":"2024-02-28T16:40:39.975451Z","shell.execute_reply.started":"2024-02-28T16:40:39.975262Z","shell.execute_reply":"2024-02-28T16:40:39.975279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predict(test, model, tokenizer)\nevaluate(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.976641Z","iopub.status.idle":"2024-02-28T16:40:39.976997Z","shell.execute_reply.started":"2024-02-28T16:40:39.976819Z","shell.execute_reply":"2024-02-28T16:40:39.976836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation = pd.DataFrame({'text': X_test[\"text\"], \n                           'y_true':y_true, \n                           'y_pred': y_pred},\n                         )\nevaluation.to_csv(\"test_predictions.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T16:40:39.984898Z","iopub.execute_input":"2024-02-28T16:40:39.985227Z","iopub.status.idle":"2024-02-28T16:40:40.021668Z","shell.execute_reply.started":"2024-02-28T16:40:39.985198Z","shell.execute_reply":"2024-02-28T16:40:40.020140Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m      2\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m:y_true, \n\u001b[1;32m      3\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred},\n\u001b[1;32m      4\u001b[0m                          )\n\u001b[1;32m      5\u001b[0m evaluation\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}]},{"cell_type":"code","source":"evaluation","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:07:23.313977Z","iopub.execute_input":"2023-12-10T14:07:23.314468Z","iopub.status.idle":"2023-12-10T14:07:23.337372Z","shell.execute_reply.started":"2023-12-10T14:07:23.314429Z","shell.execute_reply":"2023-12-10T14:07:23.336282Z"},"trusted":true},"execution_count":null,"outputs":[]}]}